{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import geemap\n",
    "import ee\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "from random import randint\n",
    "import json\n",
    "\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = Path(\"../\")\n",
    "\n",
    "os.makedirs(proj_dir / \"Data/temp\", exist_ok=True)\n",
    "\n",
    "ee_credentials = {\n",
    "    \"service_account\": \"thorr-dev@thorr-410020.iam.gserviceaccount.com\",\n",
    "    \"private_key_path\": str(proj_dir / \".env/thorr-410020-17662f251e5d.json\"),\n",
    "}\n",
    "\n",
    "geopackage_fn = proj_dir / \"Data/col_drivt_data.gpkg\" # specify the path to the geopackage file\n",
    "reaches_fn = proj_dir / \"Data/temp/reaches.shp\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaches = gpd.read_file(geopackage_fn, layer=\"BufferedReaches\")\n",
    "reaches.to_file(reaches_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "river_shp = Path(\n",
    "    proj_dir / \"Data/GIS/shapefiles/flowlines_to_reaches/bufferedReaches.shp\"\n",
    ")\n",
    "temperature_gauges_shp = Path(\n",
    "    proj_dir / \"Data/GIS/shapefiles/temperature_gauges.geojson\"\n",
    ")\n",
    "\n",
    "data_dir = Path(proj_dir, \"Data/LandsatTemperature\")\n",
    "# data_dir = Path(\"/Users/gdarkwah/eeDownloads\")\n",
    "os.makedirs(data_dir / \"reaches\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_start_end_dates(start_date, end_date, logger=None):\n",
    "    \"\"\"\n",
    "    Validate start and end dates\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    start_date: str\n",
    "        start date\n",
    "    end_date: str\n",
    "        end date\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        start and end dates\n",
    "    \"\"\"\n",
    "\n",
    "    # get today's date\n",
    "    today = datetime.datetime.today()\n",
    "\n",
    "    # convert start and end dates to datetime objects\n",
    "    if end_date is None:\n",
    "        end_date_ = today\n",
    "        if logger is not None:\n",
    "            logger.info(f\"End date is set to {end_date_}\")\n",
    "        else:\n",
    "            print(f\"End date is set to {end_date_}\")\n",
    "    else:\n",
    "        end_date_ = datetime.datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "        if end_date_ > today:\n",
    "            end_date_ = today\n",
    "            if logger is not None:\n",
    "                logger.info(f\"End date is set to {end_date_}\")\n",
    "            else:\n",
    "                print(f\"End date is set to {end_date_}\")\n",
    "\n",
    "    if start_date is None:\n",
    "        start_date_ = end_date_ - datetime.timedelta(days=90)\n",
    "        if logger is not None:\n",
    "            logger.info(f\"Start date is set to {start_date_}\")\n",
    "        else:\n",
    "            print(f\"Start date is set to {start_date_}\")\n",
    "    else:\n",
    "        start_date_ = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "\n",
    "    # check if start date is greater than end date\n",
    "    if start_date_ > end_date_:\n",
    "        start_date_ = end_date_ - datetime.timedelta(days=90)\n",
    "        if logger is not None:\n",
    "            logger.info(f\"Start date is set to {start_date_}\")\n",
    "        else:\n",
    "            print(f\"Start date is set to {start_date_}\")\n",
    "        # raise Exception(\"Start date cannot be greater than end date!\")\n",
    "\n",
    "    # check if start date is greater than today's date\n",
    "    if start_date_ > today:\n",
    "        if logger is not None:\n",
    "            logger.error(\"Start date cannot be greater than today's date!\")\n",
    "        else:\n",
    "            print(\"Start date cannot be greater than today's date!\")\n",
    "        raise Exception(\"Start date cannot be greater than today's date!\")\n",
    "\n",
    "    # check if end date is greater than today's date\n",
    "    if end_date_ > today:\n",
    "        if logger is not None:\n",
    "            logger.error(\"End date cannot be greater than today's date!\")\n",
    "        else:\n",
    "            print(\"End date cannot be greater than today's date!\")\n",
    "        raise Exception(\"End date cannot be greater than today's date!\")\n",
    "\n",
    "    # convert the start date to the first day of the month\n",
    "    start_date_ = start_date_.replace(day=1)\n",
    "\n",
    "    # convert the end date to the last day of the month\n",
    "    first_day_of_next_month = end_date_.replace(day=28) + datetime.timedelta(days=4)\n",
    "    end_date_ = first_day_of_next_month - datetime.timedelta(\n",
    "        days=first_day_of_next_month.day\n",
    "    )\n",
    "\n",
    "    # format dates as strings\n",
    "    start_date = start_date_.strftime(\"%Y-%m-%d\")\n",
    "    end_date = end_date_.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    return start_date, end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divideDates(startDate, endDate):\n",
    "    \"\"\"\n",
    "    Divide the timeframe into years\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    startDate: str\n",
    "        start date\n",
    "    endDate: str\n",
    "        end date\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        list of tuples of start and end dates\n",
    "    \"\"\"\n",
    "\n",
    "    # convert start and end dates to datetime objects\n",
    "    startDate_ = datetime.datetime.strptime(startDate, \"%Y-%m-%d\")\n",
    "    endDate_ = datetime.datetime.strptime(endDate, \"%Y-%m-%d\")\n",
    "\n",
    "    # get years from start and end dates\n",
    "    # startYear = pd.to_datetime(startDate).year\n",
    "    # endYear = pd.to_datetime(endDate).year\n",
    "    startYear = startDate_.year\n",
    "    endYear = endDate_.year\n",
    "\n",
    "    # divide the timeframe into years\n",
    "    dates = []\n",
    "    for year in range(startYear, endYear + 1):\n",
    "        if year == startYear and year == endYear:\n",
    "            dates.append([startDate, endDate])\n",
    "        elif year == startYear:\n",
    "            dates.append([startDate, f\"{year}-12-31\"])\n",
    "        elif year == endYear:\n",
    "            # if the difference end date and start of the year is less than 30 days, then replace the end date of the previous append with the end date\n",
    "            # the purpose of this is to avoid having a date range of less than 30 days (especially at the beginning of the last year)\n",
    "            if (endDate_ - datetime.datetime(year, 1, 1)).days < 45:\n",
    "                dates[-1][1] = endDate\n",
    "            else:\n",
    "                dates.append([f\"{year}-01-01\", endDate])\n",
    "        else:\n",
    "            dates.append([f\"{year}-01-01\", f\"{year}-12-31\"])\n",
    "\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepL8(image):\n",
    "    \"\"\"\n",
    "    Prepare Landsat 8 image for analysis\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    image: ee.Image\n",
    "        Landsat 8 image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ee.Image\n",
    "        prepared Landsat 8 image\n",
    "    \"\"\"\n",
    "\n",
    "    # develop masks for unwanted pixels (fill, cloud, shadow)\n",
    "    qa_mask = image.select(\"QA_PIXEL\").bitwiseAnd(int(\"11111\", 2)).eq(0)\n",
    "    saturation_mask = image.select(\"QA_RADSAT\").eq(0)\n",
    "\n",
    "    # apply scaling factors to the appropriate bands\n",
    "    def getFactorImage(factorNames):\n",
    "        factorList = image.toDictionary().select(factorNames).values()\n",
    "        return ee.Image.constant(factorList)\n",
    "\n",
    "    scaleImg = getFactorImage([\"REFLECTANCE_MULT_BAND_.|TEMPERATURE_MULT_BAND_ST_B10\"])\n",
    "    offsetImg = getFactorImage([\"REFLECTANCE_ADD_BAND_.|TEMPERATURE_ADD_BAND_ST_B10\"])\n",
    "    scaled = image.select(\"SR_B.|ST_B10\").multiply(scaleImg).add(offsetImg)\n",
    "\n",
    "    # replace original bands with scaled bands and apply masks\n",
    "    return (\n",
    "        image.addBands(scaled, overwrite=True)\n",
    "        .updateMask(qa_mask)\n",
    "        .updateMask(saturation_mask)\n",
    "    )\n",
    "\n",
    "\n",
    "def addNDVI(image):\n",
    "    \"\"\"\n",
    "    Add NDVI band to image\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    image: ee.Image\n",
    "        Landsat 8 image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ee.Image\n",
    "        Landsat 8 image with NDVI band\n",
    "    \"\"\"\n",
    "\n",
    "    # ndvi = image.expression(\n",
    "    #     \"NDVI = (NIR - red)/(NIR + red)\",\n",
    "    #     {\"red\": image.select(\"SR_B4\"), \"NIR\": image.select(\"SR_B5\")},\n",
    "    # ).rename(\"NDVI\")\n",
    "\n",
    "    ndvi = image.normalizedDifference([\"SR_B5\", \"SR_B4\"]).rename(\"NDVI\")\n",
    "\n",
    "    return image.addBands(ndvi)\n",
    "\n",
    "\n",
    "def addCelcius(image):\n",
    "    \"\"\"\n",
    "    Add Celcius band to image\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    image: ee.Image\n",
    "        Landsat 8 image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ee.Image\n",
    "        Landsat 8 image with Celcius band\n",
    "    \"\"\"\n",
    "    celcius = image.select(\"ST_B10\").subtract(273.15).rename(\"Celcius\")\n",
    "\n",
    "    return image.addBands(celcius)\n",
    "\n",
    "def prepL4(image):\n",
    "\n",
    "    # develop masks for unwanted pixels (fill, cloud, shadow)\n",
    "    qa_mask = image.select(\"QA_PIXEL\").bitwiseAnd(int(\"11111\", 2)).eq(0)\n",
    "    saturation_mask = image.select(\"QA_RADSAT\").eq(0)\n",
    "\n",
    "    # apply scaling factors to the appropriate bands\n",
    "    opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2)\n",
    "    thermalBand = image.select('ST_B6').multiply(0.00341802).add(149.0)\n",
    "\n",
    "\n",
    "    # replace original bands with scaled bands and apply masks\n",
    "    return (\n",
    "        image.addBands(opticalBands, overwrite=True)\n",
    "        .addBands(thermalBand, overwrite=True)\n",
    "        .updateMask(qa_mask)\n",
    "        .updateMask(saturation_mask)\n",
    "    )\n",
    "\n",
    "def addL4NDVI(image):\n",
    "\n",
    "    # ndvi = image.expression(\n",
    "    #     \"NDVI = (NIR - red)/(NIR + red)\",\n",
    "    #     {\"red\": image.select(\"SR_B4\"), \"NIR\": image.select(\"SR_B5\")},\n",
    "    # ).rename(\"NDVI\")\n",
    "\n",
    "    ndvi = image.normalizedDifference([\"SR_B4\", \"SR_B3\"]).rename(\"NDVI\")\n",
    "\n",
    "    return image.addBands(ndvi)\n",
    "\n",
    "def addL4Celcius(image):\n",
    "    celcius = image.select(\"ST_B6\").subtract(273.15).rename(\"Celcius\")\n",
    "\n",
    "    return image.addBands(celcius)\n",
    "\n",
    "\n",
    "def extractTempSeries(\n",
    "    reach,\n",
    "    startDate,\n",
    "    endDate,\n",
    "    # ndwi_threshold=0.2,\n",
    "    imageCollection=\"LANDSAT/LC08/C02/T1_L2\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract temperature time series for a reservoir\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    reservoir: ee.Feature\n",
    "        reservoir\n",
    "    startDate: str\n",
    "        start date\n",
    "    endDate: str\n",
    "        end date\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ee.ImageCollection\n",
    "        temperature time series\n",
    "    \"\"\"\n",
    "\n",
    "    L8 = (\n",
    "        ee.ImageCollection(imageCollection)\n",
    "        .filterDate(startDate, endDate)\n",
    "        .filterBounds(reach)\n",
    "    )\n",
    "\n",
    "    def extractData(date):\n",
    "        date = ee.Date(date)\n",
    "        # prepare Landsat 8 image and add the NDWI band, and Celcius band\n",
    "        processedL8 = (\n",
    "            L8.filterDate(date, date.advance(1, \"day\"))\n",
    "            .map(prepL8)\n",
    "            .map(addCelcius)\n",
    "            .map(addNDVI)\n",
    "            # .map(addNDWI)\n",
    "        )\n",
    "\n",
    "        # get quality NDWI and use it as the water mask\n",
    "        # ndwi = processedL8.qualityMosaic(\"NDWI\").select(\"NDWI\")\n",
    "        # waterMaskNdwi = ndwi.gte(ndwi_threshold)\n",
    "        # nonWaterMask = ndwi.lt(ndwi_threshold)\n",
    "\n",
    "        mosaic = processedL8.mosaic()\n",
    "        waterMask = mosaic.select(\"QA_PIXEL\").bitwiseAnd(int(\"10000000\", 2)).neq(0)\n",
    "        nonWaterMask = mosaic.select(\"QA_PIXEL\").bitwiseAnd(int(\"10000000\", 2)).eq(0)\n",
    "\n",
    "        # find the mean of the images in the collection\n",
    "        meanL8water = (\n",
    "            processedL8.reduce(ee.Reducer.mean())\n",
    "            # .addBands(ndwi, [\"NDWI\"], True)\n",
    "            .updateMask(waterMask).set(\"system:time_start\", date)\n",
    "        )\n",
    "        meanL8nonwater = (\n",
    "            processedL8.reduce(ee.Reducer.mean())\n",
    "            # .addBands(ndwi, [\"NDWI\"], True)\n",
    "            .updateMask(nonWaterMask).set(\"system:time_start\", date)\n",
    "        )\n",
    "\n",
    "        # get the mean temperature of the reache\n",
    "        watertemp = meanL8water.select([\"Celcius_mean\"]).reduceRegion(\n",
    "            reducer=ee.Reducer.median(),\n",
    "            # reducer=ee.Reducer.mean(),\n",
    "            geometry=reach.geometry(),\n",
    "            scale=30,\n",
    "        )\n",
    "        landtemp = meanL8nonwater.select([\"Celcius_mean\"]).reduceRegion(\n",
    "            reducer=ee.Reducer.median(),\n",
    "            # reducer=ee.Reducer.mean(),\n",
    "            geometry=reach.geometry(),\n",
    "            scale=30,\n",
    "        )\n",
    "        ndvi = meanL8nonwater.select([\"NDVI_mean\"]).reduceRegion(\n",
    "            reducer=ee.Reducer.median(),\n",
    "            # reducer=ee.Reducer.mean(),\n",
    "            geometry=reach.geometry(),\n",
    "            scale=30,\n",
    "        )\n",
    "\n",
    "        return ee.Feature(\n",
    "            None,\n",
    "            {\n",
    "                \"date\": date.format(\"YYYY-MM-dd\"),\n",
    "                \"watertemp(C)\": watertemp,\n",
    "                \"landtemp(C)\": landtemp,\n",
    "                \"NDVI\": ndvi,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    dates = ee.List(\n",
    "        L8.map(\n",
    "            lambda image: ee.Feature(None, {\"date\": image.date().format(\"YYYY-MM-dd\")})\n",
    "        )\n",
    "        .distinct(\"date\")\n",
    "        .aggregate_array(\"date\")\n",
    "    )\n",
    "\n",
    "    dataSeries = ee.FeatureCollection(dates.map(extractData))\n",
    "\n",
    "    return dataSeries\n",
    "\n",
    "def extractL4TempSeries(\n",
    "    reach,\n",
    "    startDate,\n",
    "    endDate,\n",
    "    # ndwi_threshold=0.2,\n",
    "    imageCollection=\"LANDSAT/LT04/C02/T1_L2\",\n",
    "):\n",
    "    L4 = (\n",
    "        ee.ImageCollection(imageCollection)\n",
    "        .filterDate(startDate, endDate)\n",
    "        .filterBounds(reach)\n",
    "        .filter(ee.Filter.eq(\"PROCESSING_LEVEL\", \"L2SP\"))\n",
    "    )\n",
    "\n",
    "    def extractData(date):\n",
    "        date = ee.Date(date)\n",
    "\n",
    "        processedL4 = (\n",
    "            L4.filterDate(date, date.advance(1, \"day\"))\n",
    "            .map(prepL4)\n",
    "            .map(addL4Celcius)\n",
    "            .map(addL4NDVI)\n",
    "        )\n",
    "\n",
    "        mosaic = processedL4.mosaic()\n",
    "        waterMask = mosaic.select(\"QA_PIXEL\").bitwiseAnd(int(\"10000000\", 2)).neq(0)\n",
    "        nonWaterMask = mosaic.select(\"QA_PIXEL\").bitwiseAnd(int(\"10000000\", 2)).eq(0)\n",
    "\n",
    "        # find the mean of the images in the collection\n",
    "        meanL4water = (\n",
    "            processedL4.reduce(ee.Reducer.mean())\n",
    "            # .addBands(ndwi, [\"NDWI\"], True)\n",
    "            .updateMask(waterMask).set(\"system:time_start\", date)\n",
    "        )\n",
    "        meanL4nonwater = (\n",
    "            processedL4.reduce(ee.Reducer.mean())\n",
    "            # .addBands(ndwi, [\"NDWI\"], True)\n",
    "            .updateMask(nonWaterMask).set(\"system:time_start\", date)\n",
    "        )\n",
    "\n",
    "        # get the mean temperature of the reache\n",
    "        watertemp = meanL4water.select([\"Celcius_mean\"]).reduceRegion(\n",
    "            reducer=ee.Reducer.median(),\n",
    "            # reducer=ee.Reducer.mean(),\n",
    "            geometry=reach.geometry(),\n",
    "            scale=30,\n",
    "        )\n",
    "        landtemp = meanL4nonwater.select([\"Celcius_mean\"]).reduceRegion(\n",
    "            reducer=ee.Reducer.median(),\n",
    "            # reducer=ee.Reducer.mean(),\n",
    "            geometry=reach.geometry(),\n",
    "            scale=30,\n",
    "        )\n",
    "        ndvi = meanL4nonwater.select([\"NDVI_mean\"]).reduceRegion(\n",
    "            reducer=ee.Reducer.median(),\n",
    "            # reducer=ee.Reducer.mean(),\n",
    "            geometry=reach.geometry(),\n",
    "            scale=30,\n",
    "        )\n",
    "\n",
    "        return ee.Feature(\n",
    "            None,\n",
    "            {\n",
    "                \"date\": date.format(\"YYYY-MM-dd\"),\n",
    "                \"watertemp(C)\": watertemp,\n",
    "                \"landtemp(C)\": landtemp,\n",
    "                \"NDVI\": ndvi,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    dates = ee.List(\n",
    "        L4.map(\n",
    "            lambda image: ee.Feature(None, {\"date\": image.date().format(\"YYYY-MM-dd\")})\n",
    "        )\n",
    "        .distinct(\"date\")\n",
    "        .aggregate_array(\"date\")\n",
    "    )\n",
    "\n",
    "    dataSeries = ee.FeatureCollection(dates.map(extractData))\n",
    "\n",
    "    return dataSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reachwiseExtraction(\n",
    "    reaches,\n",
    "    reach_id,\n",
    "    startDate,\n",
    "    endDate,\n",
    "    ndwi_threshold=0.2,\n",
    "    imageCollection=\"LANDSAT/LC09/C02/T1_L2\",\n",
    "    checkpoint_path=None,\n",
    "    connection=None,\n",
    "):\n",
    "    if checkpoint_path is None:\n",
    "        checkpoint = {\"river_index\": 0, \"reach_index\": 0}\n",
    "    else:\n",
    "        with open(checkpoint_path, \"r\") as f:\n",
    "            checkpoint = json.load(f)\n",
    "\n",
    "    dates = divideDates(startDate, endDate)\n",
    "    waterTempSeriesList = []\n",
    "    landTempSeriesList = []\n",
    "\n",
    "    dataSeriesList = []\n",
    "\n",
    "\n",
    "\n",
    "    if os.path.isfile(data_dir / \"reaches\" / f\"{reach_id}.csv\"):\n",
    "        existing_df = pd.read_csv(data_dir / \"reaches\" / f\"{reach_id}.csv\")\n",
    "        existing_df[\"date\"] = pd.to_datetime(existing_df[\"date\"])\n",
    "        dataSeriesList.append(existing_df)\n",
    "        \n",
    "\n",
    "    for date in dates:\n",
    "        startDate_ = date[0]\n",
    "        endDate_ = date[1]\n",
    "\n",
    "        reach = reaches.filter(ee.Filter.eq(\"reach_id\", ee.String(reach_id)))\n",
    "        # waterTempSeries, landTempSeries= extractTempSeries(\n",
    "        #     reservoir, startDate_, endDate_, ndwi_threshold, imageCollection\n",
    "        # )\n",
    "        # waterTempSeries = geemap.ee_to_pandas(waterTempSeries)\n",
    "        # landTempSeries = geemap.ee_to_pandas(landTempSeries)\n",
    "        \n",
    "        match imageCollection:\n",
    "            case \"LANDSAT/LC09/C02/T1_L2\" | \"LANDSAT/LC08/C02/T1_L2\":\n",
    "                dataSeries = extractTempSeries(\n",
    "                    reach,\n",
    "                    startDate_,\n",
    "                    endDate_,\n",
    "                    # ndwi_threshold,\n",
    "                    imageCollection,\n",
    "                )\n",
    "            case \"LANDSAT/LT04/C02/T1_L2\" | \"LANDSAT/LT05/C02/T1_L2\" | \"LANDSAT/LE07/C02/T1_L2\":\n",
    "                dataSeries = extractL4TempSeries(\n",
    "                    reach,\n",
    "                    startDate_,\n",
    "                    endDate_,\n",
    "                    # ndwi_threshold,\n",
    "                    imageCollection,\n",
    "                )\n",
    "            case _:\n",
    "                pass\n",
    "\n",
    "\n",
    "        # dataSeries = extractTempSeries(\n",
    "        #     reach,\n",
    "        #     startDate_,\n",
    "        #     endDate_,\n",
    "        #     # ndwi_threshold,\n",
    "        #     imageCollection,\n",
    "        # )\n",
    "        dataSeries = geemap.ee_to_gdf(dataSeries)\n",
    "\n",
    "        if not dataSeries.empty:\n",
    "            # print(dataSeries.head())\n",
    "\n",
    "            # convert date column to datetime\n",
    "            # waterTempSeries[\"date\"] = pd.to_datetime(waterTempSeries[\"date\"])\n",
    "            # landTempSeries[\"date\"] = pd.to_datetime(landTempSeries[\"date\"])\n",
    "            dataSeries[\"date\"] = pd.to_datetime(dataSeries[\"date\"])\n",
    "\n",
    "            # waterTempSeries[\"temp(C)\"] = (\n",
    "            #     waterTempSeries[\"temp(C)\"]\n",
    "            #     .apply(lambda x: x[\"Celcius_mean\"])\n",
    "            #     .astype(float)\n",
    "            # )\n",
    "            # landTempSeries[\"temp(C)\"] = (\n",
    "            #     landTempSeries[\"temp(C)\"]\n",
    "            #     .apply(lambda x: x[\"Celcius_mean\"])\n",
    "            #     .astype(float)\n",
    "            # )\n",
    "\n",
    "            dataSeries[\"watertemp(C)\"] = (\n",
    "                dataSeries[\"watertemp(C)\"].apply(lambda x: x[\"Celcius_mean\"]).astype(float)\n",
    "            )\n",
    "            dataSeries[\"landtemp(C)\"] = (\n",
    "                dataSeries[\"landtemp(C)\"].apply(lambda x: x[\"Celcius_mean\"]).astype(float)\n",
    "            )\n",
    "            dataSeries[\"NDVI\"] = (\n",
    "                dataSeries[\"NDVI\"].apply(lambda x: x[\"NDVI_mean\"]).astype(float)\n",
    "            )\n",
    "\n",
    "            dataSeries[\"reach_id\"] = reach_id\n",
    "\n",
    "            # append time series to list\n",
    "            # waterTempSeriesList.append(waterTempSeries)\n",
    "            # landTempSeriesList.append(landTempSeries)\n",
    "            dataSeriesList.append(dataSeries)\n",
    "\n",
    "        s_time = randint(3, 8)\n",
    "        time.sleep(s_time)\n",
    "\n",
    "    # concatenate all time series\n",
    "    # waterTempSeries_df = pd.concat(waterTempSeriesList, ignore_index=True)\n",
    "    # landTempSeries_df = pd.concat(landTempSeriesList, ignore_index=True)\n",
    "    dataSeries_df = pd.concat(dataSeriesList, ignore_index=True)\n",
    "\n",
    "    # sort by date\n",
    "    # waterTempSeries_df.sort_values(by=\"date\", inplace=True)\n",
    "    # landTempSeries_df.sort_values(by=\"date\", inplace=True)\n",
    "    dataSeries_df.sort_values(by=\"date\", inplace=True)\n",
    "    \n",
    "    dataSeries_df.drop_duplicates(subset=\"date\", inplace=True)\n",
    "    dataSeries_df.to_csv(\n",
    "        data_dir / \"reaches\" / f\"{reach_id}.csv\", index=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def runExtraction(\n",
    "    data_dir,\n",
    "    rivers,\n",
    "    reaches_gdf,\n",
    "    start_date,\n",
    "    end_date,\n",
    "    checkpoint_path=None,\n",
    "    connection=None,\n",
    "    logger=None,\n",
    "):\n",
    "    # print(start_date, end_date)\n",
    "    if checkpoint_path is None:\n",
    "        checkpoint = {\"river_index\": 0, \"reach_index\": 0}\n",
    "    else:\n",
    "        with open(checkpoint_path, \"r\") as f:\n",
    "            checkpoint = json.load(f)\n",
    "\n",
    "    unique_rivers = rivers[checkpoint[\"river_index\"] :]\n",
    "\n",
    "    for river in unique_rivers:\n",
    "        reaches_gdf[reaches_gdf[\"GNIS_Name\"] == river].to_file(\n",
    "            data_dir / \"reaches\" / \"rivers.shp\"\n",
    "        )\n",
    "        reach_ids = reaches_gdf[reaches_gdf[\"GNIS_Name\"] == river][\"reach_id\"].tolist()\n",
    "        reach_ids = reach_ids[checkpoint[\"reach_index\"] :]\n",
    "\n",
    "        reaches = geemap.shp_to_ee(data_dir / \"reaches\" / \"rivers.shp\")\n",
    "\n",
    "        if reach_ids is None:\n",
    "            ee_reach_ids = reaches.select(\"reach_id\", retainGeometry=False).getInfo()\n",
    "            reach_ids = [i[\"properties\"][\"reach_id\"] for i in ee_reach_ids[\"features\"]][\n",
    "                checkpoint[\"reach_index\"] :\n",
    "            ]\n",
    "            # reach_ids = gdf[\"reach_id\"].tolist()\n",
    "\n",
    "        for reach_id in reach_ids:\n",
    "            # Landsat9 Data\n",
    "            if datetime.datetime.strptime(end_date, \"%Y-%m-%d\") >= datetime.datetime.strptime(\"2021-10-01\", \"%Y-%m-%d\"):\n",
    "                # print(\"Landsat9\")\n",
    "                reachwiseExtraction(\n",
    "                    reaches,\n",
    "                    reach_id,\n",
    "                    max(\n",
    "                        datetime.datetime.strptime(start_date, \"%Y-%m-%d\"),\n",
    "                        datetime.datetime.strptime(\"2021-10-01\", \"%Y-%m-%d\"),\n",
    "                    ).strftime(\n",
    "                        \"%Y-%m-%d\"\n",
    "                    ),  # clip the start date to 2021-10-01\n",
    "                    end_date,\n",
    "                    # ndwi_threshold,\n",
    "                    imageCollection=\"LANDSAT/LC09/C02/T1_L2\",\n",
    "                    checkpoint_path=checkpoint_path,\n",
    "                    connection=connection,\n",
    "                )\n",
    "\n",
    "            # Landsat8 Data\n",
    "            if datetime.datetime.strptime(end_date, \"%Y-%m-%d\") >= datetime.datetime.strptime(\"2013-03-01\", \"%Y-%m-%d\"):\n",
    "                # print(\"Landsat8\")\n",
    "                reachwiseExtraction(\n",
    "                    reaches,\n",
    "                    reach_id,\n",
    "                    max(\n",
    "                        datetime.datetime.strptime(start_date, \"%Y-%m-%d\"),\n",
    "                        datetime.datetime.strptime(\"2013-03-01\", \"%Y-%m-%d\"),\n",
    "                    ).strftime(\n",
    "                        \"%Y-%m-%d\"\n",
    "                    ),  # clip the start date to 2021-10-01\n",
    "                    end_date,\n",
    "                    # ndwi_threshold,\n",
    "                    imageCollection=\"LANDSAT/LC08/C02/T1_L2\",\n",
    "                    checkpoint_path=checkpoint_path,\n",
    "                    connection=connection,\n",
    "                )\n",
    "\n",
    "            # Landsat7 Data\n",
    "            # if datetime.datetime.strptime(start_date, \"%Y-%m-%d\") >= datetime.datetime.strptime(\"1999-03-01\", \"%Y-%m-%d\") and datetime.datetime.strptime(end_date, \"%Y-%m-%d\") <= datetime.datetime.strptime(\"2012-05-31\", \"%Y-%m-%d\"):\n",
    "            if datetime.datetime.strptime(start_date, \"%Y-%m-%d\") < datetime.datetime.strptime(\"2024-01-31\", \"%Y-%m-%d\") and datetime.datetime.strptime(end_date, \"%Y-%m-%d\") > datetime.datetime.strptime(\"1999-05-01\", \"%Y-%m-%d\"):\n",
    "                # print(\"Landsat7\")\n",
    "                reachwiseExtraction(\n",
    "                    reaches,\n",
    "                    reach_id,\n",
    "                    max(\n",
    "                        datetime.datetime.strptime(start_date, \"%Y-%m-%d\"),\n",
    "                        datetime.datetime.strptime(\"1999-05-01\", \"%Y-%m-%d\"),\n",
    "                    ).strftime(\n",
    "                        \"%Y-%m-%d\"\n",
    "                    ),\n",
    "                    min(\n",
    "                        datetime.datetime.strptime(end_date, \"%Y-%m-%d\"),\n",
    "                        datetime.datetime.strptime(\"2024-01-31\", \"%Y-%m-%d\"),\n",
    "                    ).strftime(\n",
    "                        \"%Y-%m-%d\"\n",
    "                    ),\n",
    "                    # ndwi_threshold,\n",
    "                    imageCollection=\"LANDSAT/LE07/C02/T1_L2\",\n",
    "                    checkpoint_path=checkpoint_path,\n",
    "                    connection=connection,\n",
    "                )\n",
    "\n",
    "            # Landsat5 Data\n",
    "            # if datetime.datetime.strptime(start_date, \"%Y-%m-%d\") >= datetime.datetime.strptime(\"1984-03-01\", \"%Y-%m-%d\") and datetime.datetime.strptime(end_date, \"%Y-%m-%d\") <= datetime.datetime.strptime(\"2012-05-31\", \"%Y-%m-%d\"):\n",
    "            if datetime.datetime.strptime(start_date, \"%Y-%m-%d\") < datetime.datetime.strptime(\"2012-05-31\", \"%Y-%m-%d\") and datetime.datetime.strptime(end_date, \"%Y-%m-%d\") > datetime.datetime.strptime(\"1984-03-01\", \"%Y-%m-%d\"):\n",
    "                # print(\"Landsat5\")\n",
    "                reachwiseExtraction(\n",
    "                    reaches,\n",
    "                    reach_id,\n",
    "                    max(\n",
    "                        datetime.datetime.strptime(start_date, \"%Y-%m-%d\"),\n",
    "                        datetime.datetime.strptime(\"1984-03-01\", \"%Y-%m-%d\"),\n",
    "                    ).strftime(\n",
    "                        \"%Y-%m-%d\"\n",
    "                    ),\n",
    "                    min(\n",
    "                        datetime.datetime.strptime(end_date, \"%Y-%m-%d\"),\n",
    "                        datetime.datetime.strptime(\"2012-05-31\", \"%Y-%m-%d\"),\n",
    "                    ).strftime(\n",
    "                        \"%Y-%m-%d\"\n",
    "                    ),\n",
    "                    # ndwi_threshold,\n",
    "                    imageCollection=\"LANDSAT/LT05/C02/T1_L2\",\n",
    "                    checkpoint_path=checkpoint_path,\n",
    "                    connection=connection,\n",
    "                )\n",
    "\n",
    "            # Landsat4 Data\n",
    "            # if datetime.datetime.strptime(start_date, \"%Y-%m-%d\") >= datetime.datetime.strptime(\"1982-08-01\", \"%Y-%m-%d\") and datetime.datetime.strptime(end_date, \"%Y-%m-%d\") <= datetime.datetime.strptime(\"1993-06-30\", \"%Y-%m-%d\"):\n",
    "            if datetime.datetime.strptime(start_date, \"%Y-%m-%d\") < datetime.datetime.strptime(\"1993-06-30\", \"%Y-%m-%d\") and datetime.datetime.strptime(end_date, \"%Y-%m-%d\") > datetime.datetime.strptime(\"1982-08-01\", \"%Y-%m-%d\"):\n",
    "                # print(\"Landsat4\")\n",
    "                reachwiseExtraction(\n",
    "                    reaches,\n",
    "                    reach_id,\n",
    "                    max(\n",
    "                        datetime.datetime.strptime(start_date, \"%Y-%m-%d\"),\n",
    "                        datetime.datetime.strptime(\"1982-08-01\", \"%Y-%m-%d\"),\n",
    "                    ).strftime(\n",
    "                        \"%Y-%m-%d\"\n",
    "                    ),\n",
    "                    min(\n",
    "                        datetime.datetime.strptime(end_date, \"%Y-%m-%d\"),\n",
    "                        datetime.datetime.strptime(\"1993-06-30\", \"%Y-%m-%d\"),\n",
    "                    ).strftime(\n",
    "                        \"%Y-%m-%d\"\n",
    "                    ),\n",
    "                    # ndwi_threshold,\n",
    "                    imageCollection=\"LANDSAT/LT04/C02/T1_L2\",\n",
    "                    checkpoint_path=checkpoint_path,\n",
    "                    connection=connection,\n",
    "                )\n",
    "\n",
    "            checkpoint[\"reach_index\"] += 1\n",
    "            json.dump(checkpoint, open(checkpoint_path, \"w\"))\n",
    "            # if logger is not None:\n",
    "            #     logger.info(f\"Reach {reach_id} done!\")\n",
    "            # else:\n",
    "            #     print(f\"Reach {reach_id} done!\")\n",
    "\n",
    "        checkpoint[\"reach_index\"] = 0\n",
    "        checkpoint[\"river_index\"] += 1\n",
    "        json.dump(checkpoint, open(checkpoint_path, \"w\"))\n",
    "\n",
    "        # s_time = randint(30,120)\n",
    "        # time.sleep(s_time)\n",
    "        if logger is not None:\n",
    "            logger.info(f\"{river} done!\")\n",
    "        else:\n",
    "            print(f\"{river} done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reach_data(\n",
    "    reaches_shp,\n",
    "    data_dir,\n",
    "    connection,\n",
    "    ee_credentials,\n",
    "    # temperature_gauges_shp,\n",
    "    start_date,\n",
    "    end_date,\n",
    "    # ndwi_threshold=0.2,\n",
    "    # imageCollection=\"LANDSAT/LC08/C02/T1_L2\",\n",
    "    logger=None,\n",
    "):\n",
    "    service_account = ee_credentials[\"service_account\"]\n",
    "    credentials = ee.ServiceAccountCredentials(\n",
    "        service_account, ee_credentials[\"private_key_path\"]\n",
    "    )\n",
    "    ee.Initialize(credentials)\n",
    "\n",
    "    reaches_gdf = gpd.read_file(reaches_shp)\n",
    "    reaches_gdf = reaches_gdf.to_crs(epsg=4326)\n",
    "\n",
    "    rivers = reaches_gdf[\"GNIS_Name\"].unique()\n",
    "\n",
    "    try:\n",
    "        with open(data_dir / \"reaches\" / \"checkpoint.json\", \"r\") as f:\n",
    "            checkpoint = json.load(f)\n",
    "    except Exception as e:\n",
    "        if logger is not None:\n",
    "            logger.error(f\"Error: {e}\")\n",
    "        else:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "        if logger is not None:\n",
    "            logger.info(\"Creating new checkpoint...\")\n",
    "        else:\n",
    "            print(\"Creating new checkpoint...\")\n",
    "        checkpoint = {\"river_index\": 0, \"reach_index\": 0}\n",
    "        # save checkpoint\n",
    "        json.dump(checkpoint, open(data_dir / \"reaches\" / \"checkpoint.json\", \"w\"))\n",
    "\n",
    "    repeated_tries = 0\n",
    "\n",
    "    while checkpoint[\"river_index\"] < len(rivers):\n",
    "        try:\n",
    "            # extract temperature time series for each reach\n",
    "            runExtraction(\n",
    "                data_dir=data_dir,\n",
    "                rivers=rivers,\n",
    "                reaches_gdf=reaches_gdf,\n",
    "                start_date=start_date,\n",
    "                end_date=end_date,\n",
    "                checkpoint_path=data_dir / \"reaches\" / \"checkpoint.json\",\n",
    "                connection=connection,\n",
    "                logger=logger,\n",
    "            )\n",
    "            repeated_tries = 0  # reset repeated_tries\n",
    "\n",
    "        except Exception as e:\n",
    "            if logger is not None:\n",
    "                logger.error(f\"Error: {e}\")\n",
    "            else:\n",
    "                print(f\"Error: {e}\")\n",
    "            # sleep for 0.5 - 3 minutes\n",
    "            s_time = randint(15, 45)\n",
    "            if logger is not None:\n",
    "                logger.info(f\"Sleeping for {s_time} seconds...\")\n",
    "            else:\n",
    "                print(f\"Sleeping for {s_time} seconds...\")\n",
    "            time.sleep(s_time)\n",
    "\n",
    "            if logger is not None:\n",
    "                logger.info(\"Restarting from checkpoint...\")\n",
    "            else:\n",
    "                print(\"Restarting from checkpoint...\")  # restart from checkpoint\n",
    "\n",
    "            repeated_tries += 1  # increment repeated_tries\n",
    "\n",
    "            # if repeated_tries > 3, increment river_index and reset reach_index\n",
    "            if repeated_tries > 5:\n",
    "                checkpoint[\"reach_index\"] += 1\n",
    "                current_river = reaches_gdf[\"GNIS_Name\"].unique()[\n",
    "                    checkpoint[\"river_index\"]\n",
    "                ]\n",
    "                if checkpoint[\"reach_index\"] >= len(\n",
    "                    reaches_gdf[reaches_gdf[\"GNIS_Name\"] == current_river][\n",
    "                        \"reach_id\"\n",
    "                    ].tolist()\n",
    "                ):\n",
    "                    checkpoint[\"reach_index\"] = 0\n",
    "                    checkpoint[\"river_index\"] += 1\n",
    "                repeated_tries = 0\n",
    "\n",
    "                # save checkpoint\n",
    "                json.dump(\n",
    "                    checkpoint, open(data_dir / \"reaches\" / \"checkpoint.json\", \"w\")\n",
    "                )\n",
    "\n",
    "        finally:\n",
    "            # save checkpoint\n",
    "            with open(data_dir / \"reaches\" / \"checkpoint.json\", \"r\") as f:\n",
    "                checkpoint = json.load(f)\n",
    "\n",
    "    if checkpoint[\"river_index\"] >= len(rivers):\n",
    "        checkpoint[\"river_index\"] = 0\n",
    "        checkpoint[\"reach_index\"] = 0\n",
    "        json.dump(checkpoint, open(data_dir / \"reaches\" / \"checkpoint.json\", \"w\"))\n",
    "\n",
    "    if logger is not None:\n",
    "        logger.info(\"All done!\")\n",
    "    else:\n",
    "        print(\"All done!\")\n",
    "\n",
    "    # print(\"Test okay\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date, end_date = validate_start_end_dates('1982-08-01', '2024-02-29')\n",
    "\n",
    "# start_date, end_date = validate_start_end_dates('2024-01-01', '2024-02-29')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_reach_data(\n",
    "    reaches_shp=reaches_fn,\n",
    "    data_dir=data_dir,\n",
    "    ee_credentials=ee_credentials,\n",
    "    connection=None,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    logger=None\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
